{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc_distance import calc_time, great_circle_distance, build_graph\n",
    "import pandas as pd\n",
    "matrix = np.load(\"matrix_tat.npy\")\n",
    "\n",
    "joined_df = pd.read_pickle(\"tat_df.pkl\")\n",
    "start = (56.031002, 37.339808)\n",
    "\n",
    "finish = (55.755063, 37.524752)\n",
    "# start = (55.94, 37.52)\n",
    "# finish = (55.73, 37.70)\n",
    "bt = calc_time(start, finish, matrix, joined_df, transfer_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_pickle('data/bus_data.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  geopy.distance import great_circle\n",
    "def great_circle_distance(a, b):\n",
    "    \"\"\"\n",
    "    Расстояние по большой окружности\n",
    "    \"\"\"\n",
    "    return (great_circle(a, b).km/5)*3600\n",
    "\n",
    "dataframe = pd.read_pickle('data/full_df.pkl')\n",
    "matrix = np.load(\"data/full_matrix.npy\")\n",
    "start = (55.824800, 37.507686)\n",
    "dataframe['from_start'] = list(map(lambda x : great_circle_distance(start, x), dataframe['coord']))\n",
    "\n",
    "dataframe.sort_values(by='from_start')\n",
    "for idx in dataframe.index[['bus' in str(idx) for idx in dataframe.index]]:\n",
    "    dataframe.at[idx, 'coord'] = dataframe.at[idx, 'coord'][::-1]\n",
    "dataframe.to_pickle('data/full_df_2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  geopy.distance import great_circle\n",
    "\n",
    "dataframe = pd.read_pickle('data/full_df.pkl')\n",
    "\n",
    "res = len(dataframe)\n",
    "map_dict = dict(zip(dataframe.index, list(range(res))))\n",
    "matrix = [[0] * res for i in range(res)]\n",
    "\n",
    "for sid1, station_data in tqdm.tqdm(dataframe.iterrows()):\n",
    "    for sid2, dist in station_data['links'].items():\n",
    "        if sid2 not in map_dict:\n",
    "            print(f\"Station {sid2} have no coordinates, skipped\")\n",
    "            continue\n",
    "        matrix[map_dict[sid1]][map_dict[sid2]] = dist\n",
    "# print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array(matrix)\n",
    "if walk_matrix is not None:\n",
    "    matrix[matrix*walk_matrix != 0] = np.minimum(matrix, walk_matrix)[matrix*walk_matrix != 0]\n",
    "    matrix[matrix == 0] = walk_matrix[matrix == 0]\n",
    "    matrix[matrix == 0] = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matrixxx = np.load(\"data/full_matrix_23.npy.npz\")['matrix']\n",
    "matrixxx[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixxx[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixxx = np.load(\"data/walk_adf.npy\")\n",
    "matrixxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(dataframe[['bus' in str(idx) for idx in dataframe.index]]['coord'].values.tolist())[:,::-1]\n",
    "brr = arr[:,::-1]\n",
    "brr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[['bus' in str(idx) for idx in dataframe.index]]['coord'] = dataframe[['bus' in str(idx) for idx in dataframe.index]]['coord'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_time(start, finish, matrix, dataframe, transfer_cost=0):\n",
    "    \"\"\"\n",
    "    Посчитать время в секундах между А и Б для матрицы перемещений, используя координаты и названия станций из датасета\n",
    "    \"\"\"\n",
    "    station_map = dict(zip(dataframe.index, range(len(dataframe))))\n",
    "    by_walk = great_circle_distance(start, finish)\n",
    "    # print(f\"Time by walk: {by_walk:.2f}sec\")\n",
    "    dataframe['from_start'] = list(map(lambda x : great_circle_distance(start, x), dataframe['coord']))\n",
    "    dataframe['from_finish'] = list(map(lambda x : great_circle_distance(x, finish), dataframe['coord']))\n",
    "\n",
    "    best_time = by_walk\n",
    "    best_route = None\n",
    "    for fr in dataframe.sort_values(by='from_start')[:10].index:\n",
    "        print(f'Closest: fr {fr}')\n",
    "        for to in dataframe.sort_values(by='from_finish')[:10].index:\n",
    "            print(f'Closest: to {to}')\n",
    "            budget = transfer_cost + matrix[station_map[fr], station_map[to]] + dataframe['from_start'][fr] + dataframe['from_finish'][to]\n",
    "            if budget <= best_time:\n",
    "                best_time = budget\n",
    "                best_route = [fr, to]\n",
    "            best_time = min(best_time, budget)\n",
    "\n",
    "### Printing \n",
    "            print(f\"Time for route {fr}->{to}:\\t \\\n",
    "                    walk: {dataframe['from_start'][fr]:.2f} + wait: {transfer_cost:.2f} + transport:{matrix[station_map[fr]][station_map[to]]:.2f} + \\\n",
    "                    walk: {dataframe['from_finish'][to]:.2f} = {budget:.2f}sec\")\n",
    "    if best_route is not None:\n",
    "        print(f\"Best time: {best_time:.2f}sec, Best route: {dataframe.loc[best_route[0], 'name']}->{dataframe.loc[best_route[1], 'name']}\")\n",
    "        print(f\"Best time: {best_time:.2f}sec, Best route code: {best_route[0]}->{best_route[1]}\")\n",
    "    else:\n",
    "        print(f\"Best time: {best_time:.2f}sec, walking\")\n",
    "    return best_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "walk_matrix = haversine_distances(np.array(list(df['coord'].values)))*6371*speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_pickle('data/bus_data.pkl')\n",
    "df.head()\n",
    "routes = list(set(df.index))\n",
    "bus_df = pd.DataFrame(columns=df.columns)\n",
    "for st in tqdm.tqdm(routes):\n",
    "    bus_df.loc[st] = df.loc[st].iloc[0]\n",
    "    bus_df.at[st, 'links'] = {k : v  for d in df.loc[st]['links'].values.tolist() for k, v in d.items()}\n",
    "bus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_df.at[\"bus_6845\", 'links'].update(df.loc[\"bus_6845\"]['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"bus_7\"].iloc[0]\n",
    "bus_df.loc[\"bus_7\"] = df.loc[\"bus_7\"].iloc[0]\n",
    "bus_df.loc[\"bus_7\", 'links'] = {k : v  for d in df.loc[\"bus_7\"]['links'].values for k, v in d.items()}\n",
    "bus_df.loc[\"bus_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"bus_7\"]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k : v  for d in df.loc['bus_545']['links'].values.tolist() for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.at['bus_1000397', 'links'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.loc['s9744762']['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.loc['bus_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yandex_rasp import YandexRasp\n",
    "\n",
    "TOKEN='f667814b-8196-4041-a9ac-3a34518bce61'\n",
    "DOMEN = 'evgps.me'\n",
    "rasp = YandexRasp(TOKEN, DOMEN)\n",
    "all_stations = rasp.nearest_stations(\n",
    "                            lat = 55.755063,\n",
    "                            lng = 37.524752,\n",
    "                            distance = 1.0,\n",
    "                            transport_types = None,\n",
    "                            station_types = None,\n",
    "                            lang=\"ru_RU\",\n",
    "                            offset=0,\n",
    "                            limit=500000,\n",
    "                            format=\"json\")\n",
    "all_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tat import TATWalker\n",
    "from metro import MetroWalker\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from  geopy.distance import great_circle\n",
    "import numpy as np \n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph._shortest_path import floyd_warshall\n",
    "from calc_distance import calc_time, great_circle_distance, build_graph\n",
    "\n",
    "# Получить координаты, названия и прямые связи (соседние станции) для автобусов\n",
    "tat = TATWalker(all_uids_file='all_uids.npy', all_pathes_file=open(\"all_pathes\", 'rb'))\n",
    "tat_df = tat.dataframe\n",
    "# Получить координаты, названия и прямые связи (соседние станции) для метро\n",
    "xml_url = 'https://metro.mobile.yandex.net/metro/get_file?file=scheme_1.xml&ver='\n",
    "metro = MetroWalker(xml_url)\n",
    "metro_df = metro.dataframe\n",
    "# Все остановки в одной базе\n",
    "joined_df = tat_df#.append(metro_df)\n",
    "\n",
    "# Все остановки в одной базе\n",
    "coords = [[a[0], a[1]] for a in joined_df['coord'].values]\n",
    "walk_matrix = pairwise_distances(np.array(list(joined_df['coord'].values)), metric=great_circle_distance)\n",
    "threshold = 1200\n",
    "transfer_cost = 0 #Ждать на остановке 10 минут\n",
    "walk_matrix_reduced = walk_matrix.copy()\n",
    "walk_matrix_reduced[walk_matrix > threshold] = 0\n",
    "walk_matrix_reduced[walk_matrix_reduced != 0] += transfer_cost\n",
    "\n",
    "matrix = build_graph(joined_df, walk_matrix_reduced)\n",
    "\n",
    "np.save(\"matrix_tat.npy\", matrix)\n",
    "joined_df.to_pickle(\"tat_df.pkl\")\n",
    "start = (55.783273, 37.610669)\n",
    "finish = (55.778724, 37.646614)\n",
    "# start = (55.94, 37.52)\n",
    "# finish = (55.73, 37.70)\n",
    "bt = calc_time(start, finish, matrix, joined_df, transfer_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('routes_0420.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('data-101784-2020-04-08.xlsx')\n",
    "import json\n",
    "stations = json.load(open(\"stations.json\", encoding ='cp1251'))\n",
    "stations_df = pd.DataFrame(stations)\n",
    "stations_df = stations_df.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'coord'  = stations_df['geoData']['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['trip_id'] == '14150167_1_3_33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('routes_0420.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for station in stations:\n",
    "    name = station['Name']\n",
    "    \n",
    "        # name = int(re.sub(r\"[^0-9.,]+\", '', station.find('name').text))\n",
    "    # print(station['id'])\n",
    "    data[id_to_idx(station['ID'])] = {'coord': station['geoData']['coordinates'], 'name': name, 'links': {}}\n",
    "\n",
    "all_routes = sorted(list(set(df['trip_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import datetime\n",
    "    from tqdm import tqdm\n",
    "    def id_to_idx(id):\n",
    "        return f'bus_{id}'\n",
    "\n",
    "    def trip_time(fr_str, to_str):\n",
    "        def to_secs(str_time):\n",
    "            clock = str_time.split(':')\n",
    "            sec = int(clock[0])*3600 + int(clock[1])*60 + int(clock[2])\n",
    "            return sec\n",
    "        \n",
    "        diff = to_secs(to_str) - to_secs(fr_str)\n",
    "        return np.abs(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trip_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for route_id in tqdm(all_routes):\n",
    "    route = df[df['trip_id'] == route_id]\n",
    "    stops = sorted(list(set(route['stop_sequence'])))\n",
    "    for fr_num, to_num in zip(stops[:-1], stops[1:]):\n",
    "        fr = route[route['stop_sequence'] == fr_num]\n",
    "        to = route[route['stop_sequence'] == to_num]\n",
    "        if id_to_idx(fr['stop_id'].values[0]) in data and id_to_idx(to['stop_id'].values[0]) in data:\n",
    "            data[id_to_idx(fr['stop_id'].values[0])]['links'][id_to_idx(to['stop_id'])] = trip_time(fr['departure_time'].values[0], to['arrival_time'].values[0])\n",
    "\n",
    "dataframe = pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = route[route['stop_sequence'] == 3]\n",
    "fr['stop_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_idx(to['stop_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_pickle('tat_1kk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['links'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph._shortest_path import floyd_warshall\n",
    "import bs4\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "def id_to_idx(id):\n",
    "    return f'bus_{id}'\n",
    "\n",
    "def trip_time(fr_str, to_str):\n",
    "    def to_secs(str_time):\n",
    "        clock = str_time.split(':')\n",
    "        sec = int(clock[0])*3600 + int(clock[1])*60 + int(clock[2])\n",
    "        return sec\n",
    "    diff = to_secs(to_str) - to_secs(fr_str)\n",
    "    return np.abs(diff)\n",
    "\n",
    "class BusWalker():\n",
    "    def __init__(self, stations, routes_df , dataframe : pd.DataFrame=None):\n",
    "        \"\"\"\n",
    "        parse metro xml\n",
    "        \"\"\"\n",
    "        if not dataframe:\n",
    "            self.dataframe = self.parse_busdata(stations, routes_df)\n",
    "        else:\n",
    "            self.dataframe = dataframe\n",
    "\n",
    "    def parse_busdata(self, stations, routes_df):\n",
    "        data = {}\n",
    "        for station in stations:\n",
    "            name = station['Name']\n",
    "            \n",
    "                # name = int(re.sub(r\"[^0-9.,]+\", '', station.find('name').text))\n",
    "            # print(station['id'])\n",
    "            data[id_to_idx(station['ID'])] = {'coord': station['geoData']['coordinates'], 'name': name, 'links': {}}\n",
    "\n",
    "        all_routes = sorted(list(set(df['trip_id'])))\n",
    "        for route_id in tqdm(all_routes):\n",
    "            route = df[df['trip_id'] == route_id]\n",
    "            stops = sorted(list(set(route['stop_sequence'])))\n",
    "            for fr_num, to_num in zip(stops[:-1], stops[1:]):\n",
    "                fr = route[route['stop_sequence'] == fr_num]\n",
    "                to = route[route['stop_sequence'] == to_num]\n",
    "                if id_to_idx(fr['stop_id'].values[0]) in data and id_to_idx(to['stop_id'].values[0]) in data:\n",
    "                    data[id_to_idx(fr['stop_id'].values[0])]['links'][id_to_idx(to['stop_id'].values[0])] = trip_time(fr['departure_time'].values[0], to['arrival_time'].values[0])\n",
    "\n",
    "        dataframe = pd.DataFrame.from_dict(data, orient='index')        \n",
    "        return dataframe.dropna()\n",
    "\n",
    "stations = json.load(open(\"stations.json\", encoding ='cp1251'))\n",
    "df = pd.read_excel('data-101784-2020-04-08.xlsx', skiprows=1000000)\n",
    "df.to_pickle('routes_0420_2kk.pkl')\n",
    "bw = BusWalker(stations, df)\n",
    "bw.dataframe.to_pickle('tat_2kk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'kek':[0, {'sks': 123}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(pd.DataFrame({'kek':[0, {'sks': 123}]}))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]['kek'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = json.load(open(\"data/stations.json\", encoding ='cp1251'))\n",
    "page = 0\n",
    "df = pd.read_csv(f'xls/data-101784-2020-04-08-s{page}.csv', sep=';')[:1000]\n",
    "bw = BusWalker(stations, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Получить координаты, названия и прямые связи (соседние станции) для автобусов\n",
    "    tat = TATWalker(all_uids_file='all_uids.npy', all_pathes_file=open(\"all_pathes\", 'rb'))\n",
    "    tat_df = tat.dataframe\n",
    "    # Получить координаты, названия и прямые связи (соседние станции) для метро\n",
    "    xml_url = 'https://metro.mobile.yandex.net/metro/get_file?file=scheme_1.xml&ver='\n",
    "    metro = MetroWalker(xml_url)\n",
    "    metro_df = metro.dataframe\n",
    "    # Все остановки в одной базе\n",
    "    joined_df = tat_df.append(metro_df)\n",
    "\n",
    "    # Все остановки в одной базе\n",
    "    coords = [[a[0], a[1]] for a in joined_df['coord'].values]\n",
    "    walk_matrix = pairwise_distances(np.array(list(joined_df['coord'].values)), metric=great_circle_distance)\n",
    "    threshold = 1200\n",
    "    transfer_cost = 600 #Ждать на остановке 10 минут\n",
    "    walk_matrix_reduced = walk_matrix.copy()\n",
    "    walk_matrix_reduced[walk_matrix > threshold] = 0\n",
    "    walk_matrix_reduced[walk_matrix_reduced != 0] += transfer_cost\n",
    "\n",
    "    matrix = build_graph(joined_df, walk_matrix_reduced)\n",
    "\n",
    "    np.save(\"matrix.npy\", matrix)\n",
    "    joined_df.to_pickle(\"joined_df.pkl\")\n",
    "    start = (55.783273, 37.610669)\n",
    "    finish = (55.778724, 37.646614)\n",
    "    # start = (55.94, 37.52)\n",
    "    # finish = (55.73, 37.70)\n",
    "    bt = calc_time(start, finish, matrix, joined_df, transfer_cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metro import MetroWalker\n",
    "from bus import BusWalker\n",
    "from mo import MOWalker\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from  geopy.distance import great_circle\n",
    "import numpy as np \n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph._shortest_path import floyd_warshall\n",
    "from calc_distance import calc_time, great_circle_distance, build_graph\n",
    "import json \n",
    "import pandas as pd \n",
    "import logging\n",
    "import multiprocessing\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(lineno)d %(message)s\"\n",
    ")\n",
    "all_uids_file = 'data/all_uids.npy'\n",
    "all_pathes_file = open(\"data/all_pathes\", 'rb')\n",
    "xml_url = 'https://metro.mobile.yandex.net/metro/get_file?file=scheme_1.xml&ver='\n",
    "stations_file = open(\"data/stations.json\", encoding ='cp1251')\n",
    "routes_file_pattern = f'xls/data-101784-2020-04-08-s'\n",
    "matrix_file = \"data/matrix_all.npy\"\n",
    "joined_df_file = \"data/joined_df.pkl\"\n",
    "# Получить координаты, названия и прямые связи (соседние станции) для автобусов\n",
    "logging.info('Составляю словарь станций пригородных поездов и автобусов...')\n",
    "mo = MOWalker(all_uids_file=all_uids_file, all_pathes_file=all_pathes_file)\n",
    "# Получить координаты, названия и прямые связи (соседние станции) для метро\n",
    "logging.info('Составляю словарь станций метро...')\n",
    "metro = MetroWalker(xml_url)\n",
    "# Все про наземный транспаорт\n",
    "logging.info('Составляю словарь наземного транспорта города Москва...')\n",
    "stations = json.load(stations_file)\n",
    "joined_df = mo.dataframe.append(metro.dataframe)\n",
    "def join_df(filename):\n",
    "    routes_df = pd.read_csv(f'{routes_file_pattern}{page}.csv', sep=';')\n",
    "    bw = BusWalker(stations, routes_df)\n",
    "multiprocessing.map\n",
    "for page in range(8):\n",
    "    logging.info(f'{page}/8')\n",
    "    routes_df = pd.read_csv(f'{routes_file_pattern}{page}.csv', sep=';')\n",
    "    bw = BusWalker(stations, routes_df)\n",
    "    joined_df = joined_df.append(bw.dataframe)\n",
    "# Все остановки в одной базе\n",
    "joined_df.to_pickle(joined_df_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def join_df(filename):\n",
    "    routes_df = pd.read_csv(f'{routes_file_pattern}{page}.csv', sep=';')\n",
    "    bw = BusWalker(stations, routes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metro import MetroWalker\n",
    "from bus import BusWalker\n",
    "from mo import MOWalker\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from  geopy.distance import great_circle\n",
    "import numpy as np \n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph._shortest_path import floyd_warshall\n",
    "from calc_distance import calc_time, great_circle_distance, build_graph\n",
    "import json \n",
    "import pandas as pd \n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(lineno)d %(message)s\"\n",
    ")\n",
    "all_uids_file = 'data/all_uids.npy'\n",
    "all_pathes_file = open(\"data/all_pathes\", 'rb')\n",
    "xml_url = 'https://metro.mobile.yandex.net/metro/get_file?file=scheme_1.xml&ver='\n",
    "stations_file = open(\"data/stations.json\", encoding ='cp1251')\n",
    "routes_file_pattern = f'xls/data-101784-2020-04-08-s'\n",
    "matrix_file = \"data/matrix_all.npy\"\n",
    "joined_df_file = \"data/joined_df.pkl\"\n",
    "# Получить координаты, названия и прямые связи (соседние станции) для автобусов\n",
    "logging.info('Составляю словарь станций пригородных поездов и автобусов...')\n",
    "mo = MOWalker(all_uids_file=all_uids_file, all_pathes_file=all_pathes_file)\n",
    "# Получить координаты, названия и прямые связи (соседние станции) для метро\n",
    "logging.info('Составляю словарь станций метро...')\n",
    "metro = MetroWalker(xml_url)\n",
    "# Все про наземный транспаорт\n",
    "logging.info('Составляю словарь наземного транспорта города Москва...')\n",
    "stations = json.load(stations_file)\n",
    "joined_df = mo.dataframe.append(metro.dataframe)\n",
    "for page in range(8):\n",
    "    logging.info(f'{page}/8')\n",
    "    routes_df = pd.read_csv(f'{routes_file_pattern}{page}.csv', sep=';')\n",
    "    bw = BusWalker(stations, routes_df)\n",
    "    joined_df = joined_df.append(bw.dataframe)\n",
    "# Все остановки в одной базе\n",
    "joined_df.to_pickle(joined_df_file)\n",
    "\n",
    "# Все остановки в одной базе\n",
    "logging.info('Вычисляю попарные расстояния между всеми станциями...')\n",
    "walk_matrix = pairwise_distances(np.array(list(joined_df['coord'].values)), metric=great_circle_distance)\n",
    "threshold = 1200\n",
    "transfer_cost = 0 #Ждать на остановке 10 минут\n",
    "walk_matrix_reduced = walk_matrix.copy()\n",
    "walk_matrix_reduced[walk_matrix > threshold] = 0\n",
    "walk_matrix_reduced[walk_matrix_reduced != 0] += transfer_cost\n",
    "logging.info('Строю граф для всех станций и пеших маршрутов...')\n",
    "matrix = build_graph(joined_df, walk_matrix_reduced)\n",
    "logging.info('Сохраняю...')\n",
    "np.save(matrix_file, matrix)\n",
    "joined_df.to_pickle(joined_df_file)\n",
    "start = (55.783273, 37.610669)\n",
    "finish = (55.778724, 37.646614)\n",
    "# start = (55.94, 37.52)\n",
    "# finish = (55.73, 37.70)\n",
    "logging.info('Вычисляю расстояние...')\n",
    "bt = calc_time(start, finish, matrix, joined_df, transfer_cost)\n",
    "logging.info('Все')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(list(joined_df['coord'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "tree = KDTree(points, leaf_size=2)\n",
    "print(tree.query_radius(points[-10:], r=0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.query_radius(points[-10:], r=0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import numpy as np\n",
    ">>> rng = np.random.RandomState(0)\n",
    ">>> X = rng.random_sample((10, 3))  # 10 points in 3 dimensions\n",
    ">>> tree = KDTree(X, leaf_size=2)     # doctest: +SKIP\n",
    ">>> print(tree.query_radius(X[:1], r=0.3, count_only=True))\n",
    "3\n",
    ">>> ind = tree.query_radius(X[:1], r=0.3)  # doctest: +SKIP\n",
    "print(ind)  # indices of neighbors within distance 0.3\n",
    "[3 0 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc_distance import calc_time, great_circle_distance, build_graph\n",
    "import pandas as pd\n",
    "matrix_file = \"data/matrix_all.npy\"\n",
    "joined_df_file = \"data/joined_df.pkl\"\n",
    "matrix = np.load(matrix_file)\n",
    "joined_df = pd.read_pickle(joined_df_file)\n",
    "start = (56.031002, 37.339808)\n",
    "finish = (55.755063, 37.524752)\n",
    "# start = (55.94, 37.52)\n",
    "# finish = (55.73, 37.70)\n",
    "bt = calc_time(start, finish, matrix, joined_df, transfer_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metro import MetroWalker\n",
    "from bus import BusWalker\n",
    "from mo import MOWalker\n",
    "import os\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from  geopy.distance import great_circle\n",
    "import numpy as np \n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph._shortest_path import floyd_warshall\n",
    "from calc_distance import calc_time, great_circle_distance, build_graph\n",
    "import json \n",
    "import pandas as pd \n",
    "import logging\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import glob\n",
    "from functools import partial\n",
    "import tqdm\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "def join_df(routes_chunk_df, stations):\n",
    "    bw = BusWalker(stations, routes_chunk_df)\n",
    "    return bw.dataframe\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser(description=\"Поиск времени в пути в душегубке\")\n",
    "# parser.add_argument(\n",
    "#     \"--fr\",\n",
    "#     default='55.750692,37.506783',\n",
    "#     help=\"55.783273,37.610669\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--to\",\n",
    "#     default='55.758270,37.551506',\n",
    "#     help=\"55.778724,37.646614\"\n",
    "# )\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(lineno)d %(message)s\"\n",
    ")\n",
    "all_uids_file = 'data/all_uids.npy'\n",
    "all_pathes_file = open(\"data/all_pathes\", 'rb')\n",
    "xml_url = 'https://metro.mobile.yandex.net/metro/get_file?file=scheme_1.xml&ver='\n",
    "stations_file = open(\"data/stations.json\", encoding ='cp1251')\n",
    "routes_file_pattern = f'xls/data-101784-2020-04-08-s*.csv'\n",
    "matrix_file = \"data/full_matrix.npy\"\n",
    "joined_df_file = \"data/full_df.pkl\"\n",
    "speed = 3600/5\n",
    "n_processes = 64\n",
    "threshold = 1200 #Максимальное расстояние пешком в секундах\n",
    "transfer_cost = 300 #Ждать на остановке 5 минут\n",
    "\n",
    "# try:\n",
    "#     start = (float(args.fr.split(\",\")[0]), float(args.fr.split(\",\")[1]))\n",
    "#     finish = (float(args.to.split(\",\")[0]), float(args.to.split(\",\")[1]))\n",
    "#     logging.info(f'Вычисляю расстояние для {start} {finish}...')\n",
    "# except:\n",
    "#     logging.error(\"Wrong coordinates {args.fr}.{args.to}\")\n",
    "#     exit(-1)\n",
    "\n",
    "if not os.path.exists(joined_df_file):\n",
    "    logging.info(f'Нет предрассчитанного файла {joined_df_file} - парсим данные')\n",
    "    # Получить координаты, названия и прямые связи (соседние станции) для автобусов\n",
    "    logging.info('Составляю словарь станций пригородных поездов и автобусов...')\n",
    "    mo = MOWalker(all_uids_file=all_uids_file, all_pathes_file=all_pathes_file)\n",
    "    # Получить координаты, названия и прямые связи (соседние станции) для метро\n",
    "    logging.info('Составляю словарь станций метро...')\n",
    "    metro = MetroWalker(xml_url)\n",
    "    joined_df = mo.dataframe.append(metro.dataframe)\n",
    "    # Все про наземный транспаорт\n",
    "    logging.info('Составляю словарь наземного транспорта города Москва...')\n",
    "    stations = json.load(stations_file)\n",
    "    files = glob.glob(routes_file_pattern)\n",
    "    logging.info(f\"Получены {len(files)} файлов наземного транспорта типа {files[0]}\")\n",
    "    logging.info(f\"Параллельная загрузка {len(files)} файлов \")\n",
    "    process_pool = Pool(processes=len(files))\n",
    "    # def load_fn(x):\n",
    "    #     tmp_df = pd.read_csv(x, sep=';')\n",
    "    #     return tmp_df\n",
    "    dfs = process_pool.map(partial(pd.read_csv, sep=';'), files)\n",
    "    routes_df = pd.concat(dfs)\n",
    "    logging.info(f\"Длина датасета {len(routes_df)}\")\n",
    "    routes_chunks = np.array_split(routes_df, n_processes)\n",
    "    logging.info(f\"Длина чанков {list(map(len, routes_chunks))}\")\n",
    "\n",
    "\n",
    "    process_pool = Pool(processes=n_processes)\n",
    "    dfs = process_pool.map(partial(join_df, stations=stations), routes_chunks)\n",
    "    bus_data = pd.concat(dfs)\n",
    "    merged_bus = dfs[0]"
   ]
  }
 ]
}